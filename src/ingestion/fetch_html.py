import requests

API_URL = "https://battle-cats.fandom.com/api.php"


def fetch_via_api(page_title):
    """
    é€é MediaWiki API å–å¾—é é¢çš„ HTML å…§å®¹
    """
    params = {
        "action": "parse",  # æŒ‡ä»¤ï¼šè§£æé é¢
        "page": page_title,  # é é¢æ¨™é¡Œ
        "format": "json",  # å›å‚³æ ¼å¼
        "prop": "text",  # æˆ‘å€‘åªè¦è§£æå¾Œçš„ HTML æ–‡å­—
        "disablepp": 1,  # é—œé–‰ä¸€äº›ä¸å¿…è¦çš„é è™•ç†
        "redirects": 1,  # å¦‚æœæœ‰é‡å®šå‘ï¼Œè‡ªå‹•è·Ÿéš¨
    }

    # é›–ç„¶æ˜¯ APIï¼Œé‚„æ˜¯å»ºè­°å¸¶ä¸Š User-Agentï¼Œé€™æ˜¯è‰¯å¥½çš„çˆ¬èŸ²ç¦®å„€
    headers = {"User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) Bot/1.0"}

    print(f"ğŸ“¡ Calling API for page: {page_title}...")
    resp = requests.get(API_URL, params=params, headers=headers, timeout=30)
    resp.raise_for_status()

    data = resp.json()

    # æª¢æŸ¥æ˜¯å¦æœ‰éŒ¯èª¤
    if "error" in data:
        raise RuntimeError(f"API Error: {data['error']}")

    # å–å‡ºè§£æå¾Œçš„ HTML (åœ¨ ['parse']['text']['*'] è£¡é¢)
    raw_html = data["parse"]["text"]["*"]
    return raw_html


if __name__ == "__main__":
    # æ¸¬è©¦ç”¨ä¾‹
    page = "Cat_(Normal_Cat)"
    html_content = fetch_via_api(page)
    # with open("sample_api_output.html", "w", encoding="utf-8") as f:
    # f.write(html_content)
    print(html_content[:500])  # åªå°å‰ 500 å­—å…ƒçœ‹çœ‹
